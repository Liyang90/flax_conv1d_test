BufferAssignment:
allocation 0: size 512, thread-local:
 value: <2 add.6 @0> (size=512,offset=0): f32[]{:T(128)}
allocation 1: size 335790080, maybe-live-out:
 value: <4 copy.1 @0> (size=335790080,offset=0): f32[4,4099,5120]{2,0,1:T(4,128)}
allocation 2: size 335790080, parameter 0, shape |f32[4,4099,5120]| at ShapeIndex {}:
 value: <3 Arg_0.1 @0> (size=335790080,offset=0): f32[4,4099,5120]{2,0,1:T(4,128)}
allocation 3: size 20480, maybe-live-out:
 value: <6 reduce.7 @0> (size=20480,offset=0): f32[5120]{0:T(1024)}
allocation 4: size 512, constant:
 value: <5 constant.2 @0> (size=512,offset=0): f32[]{:T(128)}
allocation 5: size 32, output shape is |(f32[4,4099,5120], f32[1,1,5120])|, maybe-live-out:
 value: <7 tuple.1{} @0> (size=32,offset=0): (f32[4,4099,5120]{2,0,1:T(4,128)}, f32[1,1,5120]{2,1,0:T(1,128)})
allocation 6: size 512, thread-local:
 value: <0 Arg_0.4 @0> (size=512,offset=0): f32[]{:T(128)}
allocation 7: size 512, thread-local:
 value: <1 Arg_1.5 @0> (size=512,offset=0): f32[]{:T(128)}
allocation 8: size 0, color 1, preallocated-temp:

Total bytes used: 671602720 (640.49MiB)

Used values:
<0 Arg_0.4 @0>
 positions:
  Arg_0.4
 uses:
  add.6, operand 0
 from instruction: %Arg_0.4 = f32[]{:T(128)} parameter(0), metadata={op_name="jit(add)/jit(main)/reduce_sum[axes=(0, 1)]"}<1 Arg_1.5 @0>
 positions:
  Arg_1.5
 uses:
  add.6, operand 1
 from instruction: %Arg_1.5 = f32[]{:T(128)} parameter(1), metadata={op_name="jit(add)/jit(main)/reduce_sum[axes=(0, 1)]"}<2 add.6 @0>
 positions:
  add.6
 uses:
 from instruction: %add.6 = f32[]{:T(128)} add(f32[]{:T(128)} %Arg_0.4, f32[]{:T(128)} %Arg_1.5), metadata={op_name="jit(add)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/home/liyanglu/.local/lib/python3.10/site-packages/flax/linen/linear.py" source_line=689}<3 Arg_0.1 @0>
 positions:
  Arg_0.1
 uses:
  reduce.7, operand 0
  copy.1, operand 0
 from instruction: %Arg_0.1 = f32[4,4099,5120]{2,0,1:T(4,128)} parameter(0)<4 copy.1 @0>
 positions:
  copy.1
  tuple.1 {0}
 uses:
  tuple.1, operand 0
 from instruction: %copy.1 = f32[4,4099,5120]{2,0,1:T(4,128)} copy(f32[4,4099,5120]{2,0,1:T(4,128)} %Arg_0.1)<5 constant.2 @0>
 positions:
  constant.2
 uses:
  reduce.7, operand 1
 from instruction: %constant.2 = f32[]{:T(128)} constant(0)<6 reduce.7 @0>
 positions:
  reduce.7
  tuple.1 {1}
  bitcast.1
 uses:
  bitcast.1, operand 0
  tuple.1, operand 1
 from instruction: %reduce.7 = f32[5120]{0:T(1024)} reduce(f32[4,4099,5120]{2,0,1:T(4,128)} %Arg_0.1, f32[]{:T(128)} %constant.2), dimensions={0,1}, to_apply=%region_0.3, metadata={op_name="jit(add)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/home/liyanglu/.local/lib/python3.10/site-packages/flax/linen/linear.py" source_line=689}<7 tuple.1{} @0>
 positions:
  tuple.1 {}
 uses:
 from instruction: %tuple.1 = (f32[4,4099,5120]{2,0,1:T(4,128)}, f32[1,1,5120]{2,1,0:T(1,128)}) tuple(f32[4,4099,5120]{2,0,1:T(4,128)} %copy.1, f32[1,1,5120]{2,1,0:T(1,128)} %bitcast.1)

HloLiveRange (max 6):
  InstructionSequence:
    0:constant.2
    1:Arg_0.1
    2:reduce.7
    3:copy.1
    4:bitcast.1
    5:tuple.1
  BufferLiveRange:
    Arg_0.1{}:0-6
    copy.1{}:3-6
    constant.2{}:0-2
    reduce.7{}:2-6
    tuple.1{}:5-6
  Live ranges at 5 (peak):
    Arg_0.1: 335790080 bytes
    copy.1: 335790080 bytes
    reduce.7: 20480 bytes
    tuple.1: 16 bytes
